<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[一个简单的指数择时回测框架]]></title>
    <url>%2F2019%2F01%2F10%2F%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E6%8B%A9%E6%97%B6%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[本项目是一个简单的指数择时回测框架，整个框架结构如下： backtest/ -strategy.py -broker.py -summary.py -performance.py strategy.py文件定义了策略回测的基类Strategy,策略回测只需要继承这个基类并重写initialize、finish、on_tick方法即可： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class Strategy(ABC): &quot;&quot;&quot; 回测引擎的基类 =========== Parameters: feed: DataFrame 指数历史日期数据，包括每日信号，包含列字段为: open/high/low/close/signal/preclose 开盘价/最高价/最低价/收盘价/信号/昨收盘价 signal:&#123;1,0,-1&#125;, 取值1表示多头，0表示看平或者平仓，-1表示空头 commission: 每单位头寸交易手续费，默认为2个基点 slippage: 每单位头寸交易滑点，默认为1个基点 &quot;&quot;&quot; def __init__(self, feed, benchmark, commission=2, slippage=1): # 设置回测起始与结束日期 start_date = max(feed.index[0], benchmark.index[0]) end_date = min(feed.index[-1], benchmark.index[-1]) self.feed = feed[start_date:end_date] self._sch = Scheduler() # 调度器对象 self._logger = logger # 设置backtest, broker对象, 以及将自身实例放在调度器的runner_list中 self._sch.add_runner(self) self._sch.add_backtest(self) broker = Broker(commission, slippage) self._sch.add_broker(broker) self._sch.add_feed(feed[start_date:end_date]) self._sch.add_benchmark(benchmark[start_date:end_date]) self.stat = Summary() # 创建统计功能 self._sch.add_hook(self.stat) trade_calc = list(self.feed) # 回测日历默认为提供数据起始日范围 self._sch.add_trade_calc(trade_calc) def info(self, msg): self._logger.info(msg) def add_hook(self, *agrs, **kwargs): self._sch.add_hook(*agrs, **kwargs) def initialize(self): &quot;&quot;&quot;在回测开始前的初始化&quot;&quot;&quot; pass def run(self, tick): self.on_tick(tick) def start(self): self._sch.run() def finish(self): &quot;&quot;&quot;在回测结束后调用&quot;&quot;&quot; pass @abstractmethod def on_tick(self, tick): &quot;&quot;&quot; 回测实例必须实现的方法，并编写自己的交易逻辑 &quot;&quot;&quot; pass 在Strategy类实例化的时候会自动创建一个调度器对象Scheduler，然后通过Strategy实例的start方法就能启动调度器，而调度器会根据历史数据的一个一个时间戳不断驱动Strategy, Broker实例被调用。 为了处理不同实例之间的数据访问隔离，创建了一个Context对象并将其绑定到Strategy, Broker实例上，通过self.ctx访问共享的数据，共享的数据主要包括feed和benchmark对象，即指数的相关历史数据，benchmark为指数历史收盘价格序列，为pd.Series对象，feed为pd.DataFrame格式，包含以下字段： 日期索引 open high low close signal lastclose 2018-12-01 3450 3469 3420 3457 1 3400 signal: 交易信号，1代表看多，0代表空仓或者平仓，-1代表看空 lastclose: 代表昨收盘价价 而这个Context对象也绑定了Strategy, Broker的实例, 这就可以使得数据访问接口统一。Broker类中定义了order_open和order_close两个方法,内部根据signal的值封装了不同的处理逻辑。 summary.py文件中定义了Summary类来获取回测结果并且以属性方式提供，performance.py中则定义了许多风险收益指标计算和绘图的功能函数。 具体项目代码可以访问个人github地址：https://github.com/jeremytian2019/markettiming]]></content>
      <categories>
        <category>量化交易</category>
      </categories>
      <tags>
        <tag>量化投资</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实证资产定价与机器学习]]></title>
    <url>%2F2019%2F01%2F07%2F%E5%AE%9E%E8%AF%81%E8%B5%84%E4%BA%A7%E5%AE%9A%E4%BB%B7%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[One of our central themes is that if assets are priced rationally,variables that are related to average returns, such as size and book-to-market equity, must proxy for sensitivity to common (shared and thus undiversifiable) risk factors in returns. In such regressions, a well-specified asset-pricing model produces intercepts that are indistinguishable from 0 [Merton (1973)]. The estimated intercepts provide a simple return metric and a formal test of how well different combinations of the common factors capture the cross section of average returns. —— Fama and French (1993) 序言有效测度资产风险溢价一直以来是实证资产定价领域研究的核心问题。与传统计量方法相比，机器学习方法的运用已经引起了学界和业界越来越多的关注。本文介绍了Gu,Kelly和Xiu三位学者在芝加哥大学暑期学校上报告的一项研究1。这项研究对广义线性模型、降维方法、提升树、随机森林以及神经网络等代表性学习方法在预测风险溢价时相对传统预测方法的绩效进行了系统性的比较分析。 Why?三个方面的原因使得机器学习方法适用于金融资产预测领域： 描述和解释不同资产横截面上预期收益差异以及整体权益市场风险溢价的动态变化是实证资产定价领域研究的两条主线。测度资产风险溢价本质是个预测问题(the risk premium is the conditional expectation of a future realized excess return)，机器学习方法专门处理这些特定的任务。 可用于预测风险溢价的候选条件变量集很大（高维）。近几十年来学术研究中已经提出了数百个具有收益预测能力的特征因子23以及数十个宏观经济因子4。此外，预测因子之间通常高度相关。传统预测方法在面对高维的特征变量以及变量高相关性时显得无能为力。通过变量选择与降维技术，机器学习很适合解决这些问题。 模糊的函数形式。特征因子与目标风险溢价之间的关系是线性的吗？如果是非线性的，我们应该采用何种形式？我们需要考虑因子之间的交互效应吗？这些模型设定的问题没有较多的理论指导，不同的机器学习方法设计不同的非线性模式，通过参数惩罚和保守的模型选择标准可以用来避免过拟合以及错误发现。 Main Findings文中收集了美国市场近60年的数据（1957-2016）,94个股票特征因子以及与8个宏观经济因子的交互项以及74个行业哑变量因子形成了总共900多个信号因子作为模型输入与Size、BM和MOM三因子面板回归作为比较基准得出以下几个实证发现： 三因子基准模型样本外月度\(R^2\)为0.16%，当使用900+的信号来进行面板回归时，样本外为负，毫无意外，OLS在处理高维问题时无效。 当线性模型中考虑正则化或者降维方法时，能够解决OLS估计无效的问题。例如引入弹性网惩罚能够获得样本外正的\(R^2\)为0.09%,PCA或者PLS降维分别能获得样本外\(R^2\)为0.28%和0.18%,这说明引入正则化或者采取降维的高维回归至少能获得三因子基准模型相当的绩效，只要过度参数化得到控制。 引入非线性能很大程度上提升预测。基于树的方法和神经网络能够获得样本外月度\(R^2\)为0.27%~0.39%，基于样条平滑的广义线性模型（没有考虑交互项)并不能稳定的超过线性模型，这说明考虑预测因子之间的交互效应是非线性设定的一个重要方面。 浅层学习优于深度学习。文中设定了1~5个隐含层的神经网络，实证发现3个隐层的神经网络模型表现最好，随后绩效开始下降。此外，提升树和随机森林中树深度较浅时模型表现较号（平均不超过6个叶子节点），这可能反应了金融预测中数据较低的信号比这一事实。 当预测组合收益时非线性方法相对于线性模型的绩效提升效果更明显。例如三因子OLS模型预测标普500组合收益的\(R^2\)为-0.11%,广义线性模型的预测\(R^2\)为0.86%，而基于树方法和神经网络产生的预测\(R^2\)在1.39%到1.80%之间，预测size,value,investment,profitability以及momentum等特征因子组合可以得到类似的结果。 机器学习预测可以大大提升组合的夏普比，例如基于神经网络模型形成的多空组合可以获得2.35的年化夏普比，而三因子基准模型形成的多空组合夏普比仅为0.89。 从变量重要性分析来看，最成功的预测因子主要集中于price trends, liuquidity, volatility三大类，所有的方法都得到类似的结果。 方法描述模型模型部分在这里不做具体表述，具体可以参考论文中Section2部分，线性模型基本上使用了更为稳健的Huber损失函数。神经网络部分使用ReLU作为激活函数，文中分别拟合了1~5个隐含层的5个网络结构，各隐层神经元数目分别为\(2^n\),n为网络结构中隐层数量。 绩效评估标准文中提出了一个新的评估标准作为预测精度衡量指标，该指标在度量个股收益预测误差时更合理。 数据集划分常见样本集划分方式有Fixed,Rolling和Expanding三种方式，本文将整个样本划分为训练集（1957-1974)、验证集（1975-1986）和测试集（1987-2016）三部分，采取Fixed和Expanding相结合形式，即每年重新训练一次模型，训练集增加最近12个月数据，验证集向前滚动一年以保持验证集大小不变。 实证部分单个股票的横截面文中比较了13个模型的结果（就样本外\(R^2\)来说），其中OLS线性模型(包含交互项协变量）、ENet、GLM(group lasso)、GBRT模型损失函数使用更稳健的Huber损失而非平方损失，神经网络模型分别用了1~5个隐含层（NN1,…,NN5）。 下表显示使用参数压缩以及降维方法，预测绩效相对传统估计能获得提升。而RF和GBRT树方法以及神经网络的绩效提升更加明显，例如神经网络能均能获得0.35%以上的\(R_{oos}^2\)。此外，下表还展示了不同方法在规模大小不同的两个子样本中的预测结果，树方法和神经网络在大股票样本中特别成功，\(R_{oos} ^2\)为0.53%~0.72%。 下图展示了不同模型在每个重估日的模型复杂度。ENet模型在测试样本早期选择的特征因子数，不超过5个，2000年后，选择的特征因子数基本上稳定在20~40个的范围内。PCA典型的选择20~40个成分做预测，而PLS早期并不能找到一个可靠的成分，最终选择了3-6个成分。广义线性模型仅仅使用单个特征因子的样条函数，并没有考虑特征因子之间的交互效应，因此并没有带来明显的增量信息（相对于线性模型)，相比ENet模型，其倾向于选择更多的特征。随机森林倾向于选择浅层树作为基学习器，叶子节点的树平均为1~5个，而GBRT选择20~30个因子来划分特征空间。对于神经网络来说，“深度”的好处并没有得到体现，4~5个隐含层的神经网络表现要差于三个隐含层的网络结构。 变量重要性分析下图展示了20个重要性靠前的特征因子在模型中的相对重要性排序。基本上所有的模型在关于最有影响力的因子上达成了一致。重要性最高的因子集中在四大类：价格趋势、流动性、波动率与估值比。此外，正则化的线性模型与降维方法高度偏向于动量与反转因子。而树方法和神经网络从更广的特征集中提取预测信息。 组合预测上文分析比较了不同方法用于单个股票的预测，本节展示了不同方法预测组合收益的结果。组合水平的收益预测间接评估了不同模型的稳健性，也与组合构建环节更加相关。组合分析既可以针对预先设定的组合，例如标普500成分股组合，FF五因子形成的特征因子组合。在这里直接展示利用机器学习预测自下而上形成组合的结果。每个月末根据模型预测的个股收益进行排序形成十分位组合，通过某种加权（等权重或者市值加权）计算各个组合收益。 机器学习组合显示了良好的单调性。神经网络模型显著优于线性模型与树方法。值得注意的是，所有的模型对于非极端分位组合收益的预测比较接近，多空组合收益差表现最好的来自于NN4，其月均收益为3.3%（年化39.0%），月度波动率为4.8%（年化16.6%），样本外年化夏普比为2.35。 下表展示了组合的最大回撤、换手率与风险调整收益等指标。神经网络组合获得了最高的夏普比和更小的回撤，NN3组合最大回撤为14.8%，而三因子基准组合最大回撤为64.7%，随机森林与GBRT最大回撤分别为50.2%与35.2%,此外，NN3最大月损失为10.2%，是所有模型月损失最小的。 神经网络组合月换手率基本上在110%左右，而树方法和正则化线性模型的换手率更高。这与所有模型更多选择价格趋势相关因子以及动量因子高换手率相关。 表中还展示了不同方法组合相对于定价模型的风险调整绩效，非线性模型获得更高的alpha和信息比。FF五因子+动量六因子定价模型对线性模型的解释度平均在30%以上，而对于神经网络组合的解释度仅仅在10%左右。 下图分别展示了所有策略多头和空头组合的累计收益，神经网络模型依然是众组合中表现最好的。 笔者点评 这篇论文是一篇机器学习用于实证资产定价定价领域比较有综合性和代表性的研究。一些研究方法很值得借鉴，比如作者提出的\(R^2\)标准、以及模型比较的Diebold-Mariano检验方法。 美国市场是很成熟的市场，文中令人印象深刻的夏普比（超过2）引起不少质疑，由于文中代码并没有开源，一些实证结果很难考究。 机器学习方法在人类自然感知领域取得重大成功，但用于金融领域不是简单的套用模型。机器学习强大的拟合能力以及金融低信噪比的事实使得我们需要对整个工作流做出调整。文中对于变量处理的细节没有说明，笔者个人认为机器学习方法用于金融预测领域需要做很多基础性研究（特征工程)，比如一些降噪处理，收益的横截面上去波动性处理等等，这一块可能是成功与否的决定因素。 1. Shihao Gu, Bryan Kelly and Dacheng Xiu, 2018, Empirical Asset Pricing via Machine Learning. &#8617; 2. Green, Jeremiah, John RM Hand, and X Frank Zhang, 2013, The supraview of return predictive signals, Review of Accounting Studies 18, 692-730. &#8617; 3. Harvey, Campbell R, Yan Liu, and Heqing Zhu, 2016, … and the cross-section of expected returns, Review of Financial Studies 29, 5-68. &#8617; 4. Welch, Ivo, and Amit Goyal, 2008, A Comprehensive Look at The Empirical Performance of Equity Premium Prediction, Review of Financial Studies 21, 1455-1508. &#8617;]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>资产定价</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
